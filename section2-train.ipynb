{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section2-train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"id":"j7HY1OwKUwqg","executionInfo":{"status":"ok","timestamp":1653415942506,"user_tz":-180,"elapsed":253,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import datetime,os\n","from tensorflow.keras import layers\n","import time\n","import math"]},{"cell_type":"code","source":["is_wgan = False                # set this to loss (cross-entropy loss or Wasserstein loss)\n","is_complex_generator = False   # set this true to use more complex generator"],"metadata":{"id":"OpPBo6bbIeb6","executionInfo":{"status":"ok","timestamp":1653415961750,"user_tz":-180,"elapsed":1033,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# set seeds for reproducibility\n","np.random.seed(1)\n","tf.random.set_seed(1)"],"metadata":{"id":"MJLNz3cO3ali","executionInfo":{"status":"ok","timestamp":1653415962776,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"WbZaYCa-5wS-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load dataset\n","(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n","train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"],"metadata":{"id":"aWdpt9HPU3JM","executionInfo":{"status":"ok","timestamp":1653415962778,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#set parameters\n","latent_dim = 50\n","EPOCHS = 50\n","BATCH_SIZE = 128\n","checkpoint_path = \"/content/checkpoints/cp-{epoch:04d}.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)"],"metadata":{"id":"8IequLk4pfgV","executionInfo":{"status":"ok","timestamp":1653415963811,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def make_generator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(7*7*32, use_bias=False, input_shape=(latent_dim,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Reshape((7, 7, 32)))\n","\n","    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n","\n","    return model\n","  "],"metadata":{"id":"Z4_0q6JHU3RF","executionInfo":{"status":"ok","timestamp":1653415967802,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def make_complex_generator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(7*7*64, use_bias=False, input_shape=(latent_dim,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Reshape((7, 7, 64)))\n","    assert model.output_shape == (None, 7, 7, 64)  # Note: None is the batch size\n","\n","    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 14, 14, 64)\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 28, 28, 32)\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n","    assert model.output_shape == (None, 28, 28, 1)\n","\n","    return model"],"metadata":{"id":"Md6UvW25JLHm","executionInfo":{"status":"ok","timestamp":1653415967803,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def make_discriminator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',input_shape=[28, 28, 1]))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1))\n","\n","    return model\n"],"metadata":{"id":"X53MxjkwVN-L","executionInfo":{"status":"ok","timestamp":1653415968056,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def generate_models(summary=False):\n","  if is_complex_generator:\n","    generator = make_complex_generator_model()\n","  else:\n","    generator = make_generator_model()\n","    \n","  if summary:  \n","    generator.summary()\n","  \n","  discriminator = make_discriminator_model()\n","  if summary:\n","    discriminator.summary()\n","\n","  return generator,discriminator"],"metadata":{"id":"RqKpk0OkoP9u","executionInfo":{"status":"ok","timestamp":1653415968309,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class GAN(keras.Model):\n","    def __init__(\n","        self,\n","        discriminator,\n","        generator,\n","        latent_dim,\n","    ):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        \n","    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n","      super(GAN, self).compile()\n","      self.d_optimizer = d_optimizer\n","      self.g_optimizer = g_optimizer\n","      self.d_loss_fn = d_loss_fn\n","      self.g_loss_fn = g_loss_fn\n","\n","    def train_step(self, real_images):\n","      if isinstance(real_images, tuple):\n","          real_images = real_images[0]\n","\n","      # Get the batch size\n","      batch_size = tf.shape(real_images)[0]\n","      noise = tf.random.normal([batch_size, self.latent_dim])\n","\n","      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        generated_images = self.generator(noise, training=True)\n","\n","        real_output = self.discriminator(real_images, training=True)\n","        fake_output = self.discriminator(generated_images, training=True)\n","\n","        gen_loss = self.g_loss_fn(fake_output)\n","        disc_loss = self.d_loss_fn(real_output, fake_output)\n","\n","      gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n","      gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n","\n","      self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n","      self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n","      return {\"d_loss\": disc_loss, \"g_loss\": gen_loss}"],"metadata":{"id":"AfX0e2qCVOAw","executionInfo":{"status":"ok","timestamp":1653415969235,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class WGAN(keras.Model):\n","    def __init__(\n","        self,\n","        discriminator,\n","        generator,\n","        latent_dim,\n","        discriminator_extra_steps=3,\n","        gp_weight=10.0,\n","    ):\n","        super(WGAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.d_steps = discriminator_extra_steps\n","        self.gp_weight = gp_weight\n","\n","    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n","        super(WGAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.d_loss_fn = d_loss_fn\n","        self.g_loss_fn = g_loss_fn\n","\n","    def gradient_penalty(self, batch_size, real_images, fake_images):\n","        # Get the interpolated image\n","        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n","        diff = fake_images - real_images\n","        interpolated = real_images + alpha * diff\n","\n","        with tf.GradientTape() as gp_tape:\n","            gp_tape.watch(interpolated)\n","            # 1. Get the discriminator output for this interpolated image.\n","            pred = self.discriminator(interpolated, training=True)\n","\n","        # 2. Calculate the gradients w.r.t to this interpolated image.\n","        grads = gp_tape.gradient(pred, [interpolated])[0]\n","        # 3. Calculate the norm of the gradients.\n","        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","        gp = tf.reduce_mean((norm - 1.0) ** 2)\n","        return gp\n","\n","    def train_step(self, real_images):\n","        if isinstance(real_images, tuple):\n","            real_images = real_images[0]\n","\n","        # Get the batch size\n","        batch_size = tf.shape(real_images)[0]\n","\n","        for i in range(self.d_steps):\n","            # Get the latent vector\n","            random_latent_vectors = tf.random.normal(\n","                shape=(batch_size, self.latent_dim)\n","            )\n","            with tf.GradientTape() as tape:\n","                # Generate fake images from the latent vector\n","                fake_images = self.generator(random_latent_vectors, training=True)\n","                # Get the logits for the fake images\n","                fake_logits = self.discriminator(fake_images, training=True)\n","                # Get the logits for the real images\n","                real_logits = self.discriminator(real_images, training=True)\n","\n","                # Calculate the discriminator loss using the fake and real image logits\n","                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n","                # Calculate the gradient penalty\n","                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n","                # Add the gradient penalty to the original discriminator loss\n","                d_loss = d_cost + gp * self.gp_weight\n","\n","            # Get the gradients w.r.t the discriminator loss\n","            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","            # Update the weights of the discriminator using the discriminator optimizer\n","            self.d_optimizer.apply_gradients(\n","                zip(d_gradient, self.discriminator.trainable_variables)\n","            )\n","\n","        # Train the generator\n","        # Get the latent vector\n","        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        with tf.GradientTape() as tape:\n","            # Generate fake images using the generator\n","            generated_images = self.generator(random_latent_vectors, training=True)\n","            # Get the discriminator logits for fake images\n","            gen_img_logits = self.discriminator(generated_images, training=True)\n","            # Calculate the generator loss\n","            g_loss = self.g_loss_fn(gen_img_logits)\n","\n","        # Get the gradients w.r.t the generator loss\n","        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n","        # Update the weights of the generator using the generator optimizer\n","        self.g_optimizer.apply_gradients(\n","            zip(gen_gradient, self.generator.trainable_variables)\n","        )\n","        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"],"metadata":{"id":"b0r_keDuJzj2","executionInfo":{"status":"ok","timestamp":1653415970259,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# tensorboard to view loss graphs\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","print(logdir)"],"metadata":{"id":"dGSwNPbA51Nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run tensorboard\n","%tensorboard --logdir logs"],"metadata":{"id":"SHNtAPID54Da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_gan():\n","  # build models\n","  generator,discriminator=generate_models()\n","\n","  # Build GAN model.\n","  gan = GAN(\n","      discriminator=discriminator,\n","      generator=generator,\n","      latent_dim=latent_dim\n","  )\n","\n","  # generate optimizers and loss functions\n","  generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","  discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","\n","  # Helper function to compute cross entropy loss\n","  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","  def discriminator_loss(real_output, fake_output):\n","      real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","      total_loss = real_loss + fake_loss\n","      return total_loss\n","\n","  # for generator, we assign labels as 1 because it is trained to maximize discriminator loss,\n","  # equivalently, it minimize the loss with opposite label (1 for fake images)\n","  def generator_loss(fake_output):\n","      return cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","\n","  # Compile the WGAN model.\n","  gan.compile(\n","      d_optimizer=discriminator_optimizer,\n","      g_optimizer=generator_optimizer,\n","      g_loss_fn=generator_loss,\n","      d_loss_fn=discriminator_loss,\n","  )\n","\n","  return gan"],"metadata":{"id":"7F2qTXKEtyd6","executionInfo":{"status":"ok","timestamp":1653415977034,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def train_gan():\n","\n","  # get gan model\n","  gan = build_gan()\n","\n","  # create checkpoints\n","  STEPS_PER_EPOCH = int(math.ceil(train_images.shape[0] / BATCH_SIZE))\n","  SAVE_PERIOD = 10 # save after each SAVE_PERIOD epochs\n","  \n","  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","      filepath=checkpoint_path,\n","      save_weights_only=True,verbose=1,save_freq=SAVE_PERIOD*STEPS_PER_EPOCH)\n","\n","  # start training\n","  gan.fit(train_images, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[tensorboard_callback,model_checkpoint_callback])\n","\n","  return gan\n"],"metadata":{"id":"-mb5XV-UrY3Q","executionInfo":{"status":"ok","timestamp":1653415977034,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def build_wgan():\n","  \n","  # Build the optimizer for both networks\n","  generator_optimizer = keras.optimizers.Adam(\n","      learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n","  )\n","  discriminator_optimizer = keras.optimizers.Adam(\n","      learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n","  )\n","\n","  # Define the loss functions for the discriminator,\n","  # min (fake_loss - real_loss).\n","  def discriminator_loss(real_img, fake_img):\n","      real_loss = tf.reduce_mean(real_img)\n","      fake_loss = tf.reduce_mean(fake_img)\n","      return fake_loss - real_loss\n","\n","\n","  # Define the loss functions for the generator.\n","  # min (-fake_loss)\n","  def generator_loss(fake_img):\n","      return -tf.reduce_mean(fake_img)\n","\n","  # build models\n","  generator,discriminator=generate_models()\n","\n","  # Instantiate the WGAN model.\n","  wgan = WGAN(\n","      discriminator=discriminator,\n","      generator=generator,\n","      latent_dim=latent_dim,\n","      discriminator_extra_steps=3,\n","  )\n","\n","  # Compile the WGAN model.\n","  wgan.compile(\n","      d_optimizer=discriminator_optimizer,\n","      g_optimizer=generator_optimizer,\n","      g_loss_fn=generator_loss,\n","      d_loss_fn=discriminator_loss,\n","  )\n","\n","  return wgan"],"metadata":{"id":"7O29rlL9KVXH","executionInfo":{"status":"ok","timestamp":1653415977034,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def train_wgan():\n","\n","  # get gan model\n","  wgan = build_wgan()\n","\n","  # create checkpoints\n","  STEPS_PER_EPOCH = int(math.ceil(train_images.shape[0] / BATCH_SIZE))\n","  SAVE_PERIOD = 10 # save after each SAVE_PERIOD epochs\n","  \n","  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","      filepath=checkpoint_path,\n","      save_weights_only=True,verbose=1,save_freq=SAVE_PERIOD*STEPS_PER_EPOCH)\n","  \n","  # Start training the model.\n","  wgan.fit(train_images, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[tensorboard_callback,model_checkpoint_callback])\n","\n","  return wgan\n"],"metadata":{"id":"Voi9TDbEKXpO","executionInfo":{"status":"ok","timestamp":1653415978616,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def plot_images(generator):\n","\n","  num = 100 # number of images to generate\n","  num_row = 10\n","  num_col = 10\n","\n","  # draw std. normal variables from latent space\n","  np.random.seed(0)\n","  rand_vars = np.random.normal(size=(num,latent_dim))\n","\n","  # plot images\n","  fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n","  for i in range(num):\n","      z_sample = np.array([rand_vars[i]])\n","      predictions = generator.predict(z_sample)\n","      digit = predictions[0, :, :, 0] * 127.5 + 127.5\n","      ax = axes[i//num_col, i%num_col]\n","      ax.imshow(digit, cmap='gray')\n","  plt.tight_layout()\n","  plt.show()\n"],"metadata":{"id":"0VCu1TBbw3iD","executionInfo":{"status":"ok","timestamp":1653415980717,"user_tz":-180,"elapsed":2,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["def get_checkpoint_model(epoch):\n","  cp = checkpoint_path.format(epoch=epoch)\n","  gan = build_gan()\n","  gan.load_weights(cp)\n","  return gan\n"],"metadata":{"id":"i8ky7FK9NvME","executionInfo":{"status":"ok","timestamp":1653415981077,"user_tz":-180,"elapsed":2,"user":{"displayName":"Ömer Faruk Çavaş","userId":"04477100071756028506"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# start training\n","if is_wgan:\n","  gan = train_wgan()\n","else:\n","  gan = train_gan()"],"metadata":{"id":"HZj-RuHkRfcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_images(gan.generator) # plot images generated from model after all epochs"],"metadata":{"id":"BUt68EmoxXBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_images(get_checkpoint_model(epoch = 10).generator)  # plot images for specific checkpoint models (epochs with multiple of 10s) "],"metadata":{"id":"QW7VNsbfxXAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === BELOW CODES ARE FOR SAVING AND DOWNLOADING TRAINED MODELS ==="],"metadata":{"id":"9c8ZbKhfPXs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save trained model (after all epochs)\n","gan.generator.save(\"gan_generator\")\n","gan.discriminator.save(\"gan_discriminator\")"],"metadata":{"id":"eUFocUoVxXCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zip saved model folders to download\n","!zip -r /content/gan_generator.zip /content/gan_generator\n","!zip -r /content/gan_discriminator.zip /content/gan_discriminator"],"metadata":{"id":"oarshHc8OdDz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save trained checkpoint models\n","epoch = 10\n","get_checkpoint_model(epoch = epoch).generator.save(\"gan_generator-\"+str(epoch))\n","get_checkpoint_model(epoch = epoch).discriminator.save(\"gan_discriminator-\"+str(epoch))\n"],"metadata":{"id":"iF0bdVoiUtgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zip saved model folders to download\n","!zip -r /content/gan_generator-10.zip /content/gan_generator-10\n","!zip -r /content/gan_discriminator-10.zip /content/gan_discriminator-10"],"metadata":{"id":"O4Nglu885mcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zip checkpoint folder to download \n","!zip -r /content/checkpoints.zip /content/checkpoints\n"],"metadata":{"id":"zjtNeyCWgCrY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"O0W5xdrIgCt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FAzrcHWRUtjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lS5riL8U8WZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"GmqaQxZnnrUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"4rThOHXGvx58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"uLTUp4GJg1t2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"cnLIJQxt9O6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"IrbD2tFFUz1t"},"execution_count":null,"outputs":[]}]}