{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section2-eval.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKlPyJfsrdzO5t9i5u764T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3iFlrbVQ09ac"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import datetime, os\n","import matplotlib.pyplot as plt\n","from math import floor\n","from numpy import expand_dims\n","from numpy import log\n","from numpy import mean\n","from numpy import std\n","from numpy import exp"]},{"cell_type":"code","source":["# we first upload zip files (gan_generator.zip,gan_discriminator.zip or wgan_generator.zip,wgan_discriminator.zip) to colab "],"metadata":{"id":"max8tqSfGQnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# unzip saved models to load into keras object \n","!unzip /content/wgan_generator.zip      #replace with gan_generator for binary cross entropy loss\n","!unzip /content/wgan_discriminator.zip  #replace with gan_discriminator for binary cross entropy loss"],"metadata":{"id":"xnkhmYP_1pZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load encoder and decoder models into keras objects\n","generator = keras.models.load_model(\"/content/wgan_generator\")          #replace with gan_generator for binary cross entropy loss\n","discriminator = keras.models.load_model(\"/content/wgan_discriminator\")  #replace with gan_discriminator for binary cross entropy loss"],"metadata":{"id":"5MeuuWe9DO5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_images(generator):\n","\n","  latent_dim = 50\n","  num = 100 # number of images to generate\n","  num_row = 10\n","  num_col = 10\n","\n","  # draw std. normal variables from latent space\n","  np.random.seed(0)\n","  rand_vars = np.random.normal(size=(num,latent_dim))\n","\n","  # plot images\n","  fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n","  for i in range(num):\n","      z_sample = np.array([rand_vars[i]])\n","      predictions = generator.predict(z_sample)\n","      digit = predictions[0, :, :, 0] * 127.5 + 127.5\n","      ax = axes[i//num_col, i%num_col]\n","      ax.imshow(digit, cmap='gray')\n","  plt.tight_layout()\n","  plt.show()"],"metadata":{"id":"F1BP_zDwRPV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_images(generator)"],"metadata":{"id":"ODi0uBDVEO8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find inception score to evaluate generated images "],"metadata":{"id":"vj2rTJ4l5661"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_images():\n","  latent_dim = 50\n","  num = 100 # number of images to generate\n","  num_row = 10\n","  num_col = 10\n","\n","  # draw std. normal variables from latent space\n","  np.random.seed(0)\n","  rand_vars = np.random.normal(size=(num,latent_dim))\n","  predictions = generator.predict(rand_vars)\n","  digit = predictions * 127.5 + 127.5\n","  return digit"],"metadata":{"id":"JXEykCPn564P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_mnist_classifier():\n","\n","  # Model / data parameters\n","  num_classes = 10\n","  input_shape = (28, 28, 1)\n","\n","  # the data, split between train and test sets\n","  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","  # Scale images to the [0, 1] range\n","  x_train = x_train.astype(\"float32\") / 255\n","  x_test = x_test.astype(\"float32\") / 255\n","  # Make sure images have shape (28, 28, 1)\n","  x_train = np.expand_dims(x_train, -1)\n","  x_test = np.expand_dims(x_test, -1)\n","  print(\"x_train shape:\", x_train.shape)\n","  print(x_train.shape[0], \"train samples\")\n","  print(x_test.shape[0], \"test samples\")\n","\n","\n","  # convert class vectors to binary class matrices\n","  y_train = keras.utils.to_categorical(y_train, num_classes)\n","  y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","  model = keras.Sequential(\n","      [\n","          keras.Input(shape=input_shape),\n","          layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n","          layers.MaxPooling2D(pool_size=(2, 2)),\n","          layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n","          layers.MaxPooling2D(pool_size=(2, 2)),\n","          layers.Flatten(),\n","          layers.Dropout(0.5),\n","          layers.Dense(num_classes, activation=\"softmax\"),\n","      ]\n","  )\n","\n","  model.summary()\n","\n","  batch_size = 128\n","  epochs = 10\n","\n","  model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","  model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n","  return model"],"metadata":{"id":"GpNoN5t-7RV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_inception_score(images, model, n_split=10, eps=1E-16):\n","\n","\t# enumerate splits of images/predictions\n","\tscores = list()\n","\tn_part = floor(images.shape[0] / n_split)\n","\tfor i in range(n_split):\n","\t\t# retrieve images\n","\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n","\t\tsubset = images[ix_start:ix_end]\n","\t\t# predict p(y|x)\n","\t\tp_yx = model.predict(subset)\n","\t\t# calculate p(y)\n","\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n","\t\t# calculate KL divergence using log probabilities\n","\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n","\t\t# sum over classes\n","\t\tsum_kl_d = kl_d.sum(axis=1)\n","\t\t# average over images\n","\t\tavg_kl_d = mean(sum_kl_d)\n","\t\t# undo the log\n","\t\tis_score = exp(avg_kl_d)\n","\t\t# store\n","\t\tscores.append(is_score)\n","\t# average across images\n","\tis_avg, is_std = mean(scores), std(scores)\n","\treturn is_avg, is_std"],"metadata":{"id":"oTdWyrNq81Iz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = get_images()"],"metadata":{"id":"7ff_Lsas561p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = generate_mnist_classifier()"],"metadata":{"id":"J9AzGdyp56zA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_inception_score(images, model)"],"metadata":{"id":"G0YFo4kt56wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"P0d4UPP3C6e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"6MZv5CHjC6cj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"i5H3vlof56rW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"QBTVSDp9DO7X"},"execution_count":null,"outputs":[]}]}